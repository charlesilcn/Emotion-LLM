{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 社交媒体数据高级情感分析演示\n",
    "\n",
    "本Notebook演示如何使用本项目进行社交媒体数据的高级情感分析。通过结合传统NLP技术和现代大语言模型(LLM)，我们可以实现更准确、更深入的情感分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# 导入项目模块\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import ChineseTextPreprocessor\n",
    "from src.analysis.llm_sentiment_analyzer import LLMSentimentAnalyzer\n",
    "from src.analysis.traditional_sentiment_analyzer import TraditionalSentimentAnalyzer\n",
    "from src.visualization.visualizer import SentimentVisualizer\n",
    "from config import PROCESSED_DATA_DIR, OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤1: 数据加载\n",
    "\n",
    "首先，我们需要加载社交媒体数据。这里我们可以加载自己的数据文件，或者使用项目生成的示例数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader()\n",
    "\n",
    "# 生成示例数据（如果没有实际数据）\n",
    "def generate_sample_data():\n",
    "    \n",
    "    # 创建示例数据\n",
    "    sample_data = [\n",
    "        {\"text\": \"我非常喜欢这个产品，质量很好，价格也很合理！\", \"source\": \"微博\", \"date\": \"2023-06-15\"},\n",
    "        {\"text\": \"服务态度很差，等了很久都没人理我，不会再来了。\", \"source\": \"微信\", \"date\": \"2023-06-16\"},\n",
    "        {\"text\": \"产品一般般，没有特别惊艳的地方，但也没有明显缺点。\", \"source\": \"小红书\", \"date\": \"2023-06-17\"},\n",
    "        {\"text\": \"物流速度太快了，昨天才下单今天就收到了，包装也很精美！\", \"source\": \"淘宝\", \"date\": \"2023-06-18\"},\n",
    "        {\"text\": \"完全不符合描述，实物和图片差距很大，非常失望。\", \"source\": \"京东\", \"date\": \"2023-06-19\"},\n",
    "        {\"text\": \"性价比很高，超出预期，推荐给大家！\", \"source\": \"抖音\", \"date\": \"2023-06-20\"},\n",
    "        {\"text\": \"客服很耐心，解决问题很及时，给个赞！\", \"source\": \"拼多多\", \"date\": \"2023-06-21\"},\n",
    "        {\"text\": \"质量问题很严重，用了一天就坏了，售后服务也不好。\", \"source\": \"天猫\", \"date\": \"2023-06-22\"},\n",
    "        {\"text\": \"整体还不错，就是物流有点慢，其他都很满意。\", \"source\": \"闲鱼\", \"date\": \"2023-06-23\"},\n",
    "        {\"text\": \"这是我用过的最差的产品，没有之一，强烈不推荐！\", \"source\": \"美团\", \"date\": \"2023-06-24\"},\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(sample_data)\n",
    "    return df\n",
    "\n",
    "# 加载数据（使用示例数据）\n",
    "df = generate_sample_data()\n",
    "\n",
    "# 显示前几行数据\n",
    "print(f\"加载了 {len(df)} 条数据\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤2: 数据预处理\n",
    "\n",
    "对文本数据进行清洗和预处理，包括移除URL、用户名、表情符号等，以便进行后续分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建中文文本预处理器\n",
    "preprocessor = ChineseTextPreprocessor()\n",
    "\n",
    "# 预处理数据\n",
    "processed_df = preprocessor.process_dataframe(df, 'text')\n",
    "\n",
    "# 显示处理后的数据\n",
    "print(f\"预处理后保留了 {len(processed_df)} 条数据\")\n",
    "processed_df[[\"text\", \"text_cleaned\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤3: 情感分析\n",
    "\n",
    "使用传统方法和LLM方法进行情感分析。这里我们会先使用TextBlob进行传统情感分析，然后如果配置了OpenAI API密钥，会使用LLM进行更高级的情感分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用传统方法进行情感分析\n",
    "traditional_analyzer = TraditionalSentimentAnalyzer()\n",
    "df_with_traditional = traditional_analyzer.analyze_dataframe(processed_df, 'text_cleaned')\n",
    "\n",
    "# 显示传统分析结果\n",
    "print(\"传统情感分析结果:\")\n",
    "df_with_traditional[[\"text\", \"textblob_sentiment\", \"textblob_polarity\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用LLM进行高级情感分析（如果有API密钥）\n",
    "if OPENAI_API_KEY:\n",
    "    try:\n",
    "        print(\"使用LLM进行高级情感分析...\")\n",
    "        llm_analyzer = LLMSentimentAnalyzer(model_name='gpt-3.5-turbo')\n",
    "        \n",
    "        # 分析单个文本作为演示\n",
    "        sample_text = df_with_traditional['text'].iloc[0]\n",
    "        print(f\"\n分析示例文本: {sample_text}\n\")\n",
    "        \n",
    "        # 情感分析\n",
    "        sentiment_result = llm_analyzer.analyze_sentiment(sample_text)\n",
    "        print(\"LLM情感分析结果:")\n",
    "        for key, value in sentiment_result.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "        \n",
    "        # 情绪分析\n",
    "        emotion_result = llm_analyzer.analyze_emotion(sample_text)\n",
    "        print(\"\nLLM情绪分析结果:")\n",
    "        print(f\"  主要情绪: {emotion_result.get('primary_emotion', '无')}\")\n",
    "        print(\"  情绪得分:")\n",
    "        for emotion, score in emotion_result.get('emotion_scores', {}).items():\n",
    "            print(f\"    {emotion}: {score:.2f}\")\n",
    "        \n",
    "        # 对整个数据集进行分析\n",
    "        print(\"\n对整个数据集进行LLM分析...\")\n",
    "        final_df = llm_analyzer.analyze_dataframe(df_with_traditional, 'text_cleaned')\n",
    "        \n",
    "        # 显示最终结果\n",
    "        print(\"\nLLM分析结果示例:")\n",
    "        result_cols = ['text', 'sentiment_sentiment', 'sentiment_score', 'emotion_primary_emotion']\n",
    "        display(final_df[result_cols].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"LLM分析出错: {e}\")\n",
    "        final_df = df_with_traditional.copy()\n",
    "else:\n",
    "    print(\"未配置OpenAI API密钥，仅使用传统情感分析结果\")\n",
    "    final_df = df_with_traditional.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤4: 结果可视化\n",
    "\n",
    "使用可视化工具来直观展示情感分析结果，包括情感分布、情绪分析等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建可视化器\n",
    "visualizer = SentimentVisualizer()\n",
    "\n",
    "# 确定情感列和得分列\n",
    "if 'sentiment_sentiment' in final_df.columns:\n",
    "    sentiment_col = 'sentiment_sentiment'\n",
    "    score_col = 'sentiment_score'\n",
    "    emotion_cols = [col for col in final_df.columns if col.startswith('emotion_score_')]\n",
    "else:\n",
    "    sentiment_col = 'textblob_sentiment'\n",
    "    score_col = 'textblob_polarity'\n",
    "    emotion_cols = []  # 传统方法没有情绪分析\n",
    "\n",
    "# 1. 绘制情感分布饼图\n",
    "print(\"绘制情感分布饼图...\")\n",
    "visualizer.sentiment_distribution(final_df, sentiment_col, title='文本情感分布')\n",
    "\n",
    "# 2. 绘制情感得分分布图\n",
    "print(\"绘制情感得分分布图...\")\n",
    "visualizer.sentiment_score_distribution(final_df, score_col, title='情感得分分布')\n",
    "\n",
    "# 3. 如果有情绪分析结果，绘制情绪相关图表\n",
    "if emotion_cols:\n",
    "    print(\"绘制情绪条形图...\")\n",
    "    visualizer.emotion_bar_chart(final_df, emotion_cols, title='情绪得分分布')\n",
    "\n",
    "# 4. 创建词云（如果数据量足够）\n",
    "print(\"创建词云图...\")\n",
    "# 合并所有文本\n",
    "all_texts = final_df['text'].tolist()\n",
    "visualizer.create_wordcloud(all_texts, title='文本关键词云')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤5: 创建综合分析仪表盘\n",
    "\n",
    "生成一个综合的分析仪表盘，包含所有重要的可视化结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建综合仪表盘\n",
    "print(\"创建综合分析仪表盘...\")\n",
    "dashboard_results = visualizer.create_summary_dashboard(\n",
    "    final_df,\n    sentiment_column=sentiment_col,\n    score_column=score_col,\n    emotion_columns=emotion_cols,\n    text_column='text',\n    save=True\n",
    ")\n",
    "\n",
    "print(\"仪表盘创建完成！可视化结果已保存到 visualizations 目录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤6: 保存分析结果\n",
    "\n",
    "将分析结果保存到文件，便于后续使用或分享。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存分析结果\n",
    "output_path = os.path.join(PROCESSED_DATA_DIR, 'analysis_results_demo.csv')\n",
    "final_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    f"分析结果已保存到: {output_path}\n",
    "\n",
    "# 显示完整的分析结果列\n",
    "print(\"分析结果包含的列:\")\n",
    "for i, col in enumerate(final_df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# 显示前几行完整结果\n",
    "print(\"\n前5行完整结果:\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结与下一步\n",
    "\n",
    "通过本演示，我们完成了以下步骤：\n",
    "1. 加载并预览了社交媒体数据\n",
    "2. 对文本进行了预处理，去除了噪声\n",
    "3. 使用传统方法和LLM进行了情感分析\n",
    "4. 通过可视化直观展示了分析结果\n",
    "5. 创建了综合分析仪表盘\n",
    "6. 保存了分析结果\n",
    "\n",
    "### 可能的下一步：\n",
    "\n",
    "1. **使用更多数据**：使用真实的大规模社交媒体数据集\n",
    "2. **尝试不同的LLM模型**：比较不同模型的分析效果\n",
    "3. **定制分析维度**：根据特定业务需求调整分析维度\n",
    "4. **实时分析**：开发实时数据流的情感分析系统\n",
    "5. **情感变化趋势**：分析情感随时间的变化趋势\n",
    "6. **主题建模结合**：将情感分析与主题建模结合，分析不同主题的情感倾向\"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
import os
import json
import logging
import time
import requests
from typing import Dict, List, Optional, Union, Any

import pandas as pd
from tqdm import tqdm

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# å°è¯•ä¸åŒçš„LangChainå¯¼å…¥æ–¹å¼ä»¥é€‚åº”ä¸åŒç‰ˆæœ¬
try:
    # æ–°ç‰ˆæœ¬LangChainå¯¼å…¥æ–¹å¼
    from langchain_openai.chat_models import ChatOpenAI
    logger.info("ä½¿ç”¨æ–°ç‰ˆæœ¬LangChainå¯¼å…¥")
except ImportError:
    try:
        # æ—§ç‰ˆæœ¬LangChainå¯¼å…¥æ–¹å¼
        from langchain.chat_models import ChatOpenAI
        logger.info("ä½¿ç”¨æ—§ç‰ˆæœ¬LangChainå¯¼å…¥")
    except ImportError:
        logger.warning("æœªæ‰¾åˆ°ChatOpenAIï¼ŒOpenAIåŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†HuggingFaceåŠŸèƒ½ä»å¯ä½¿ç”¨")
        ChatOpenAI = None

# å°è¯•ä¸åŒçš„å¯¼å…¥è·¯å¾„ä»¥é€‚åº”ä¸åŒç‰ˆæœ¬çš„LangChain
try:
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.chains import LLMChain
    logger.info("ä½¿ç”¨langchain_coreæ¨¡å—å¯¼å…¥")
except ImportError:
    try:
        from langchain.prompts import ChatPromptTemplate
        from langchain.chains import LLMChain
        logger.info("ä½¿ç”¨langchainæ¨¡å—å¯¼å…¥")
    except ImportError:
        logger.warning("æœªæ‰¾åˆ°å¿…è¦çš„LangChainæ¨¡å—")
        ChatPromptTemplate = None
        LLMChain = None

# æ·»åŠ Hugging Faceæ”¯æŒ - ä½¿ç”¨æ¡ä»¶å¯¼å…¥ï¼Œç¡®ä¿æ²¡æœ‰torchæ—¶ä¹Ÿèƒ½è¿è¡ŒåŸºæœ¬åŠŸèƒ½
try:
    import torch
    logger.info("æˆåŠŸå¯¼å…¥torch")
except ImportError:
    logger.warning("æœªæ‰¾åˆ°torchæ¨¡å—ï¼Œå°†ä½¿ç”¨è½»é‡çº§é™çº§æ–¹æ¡ˆ")
    torch = None

try:
    if torch is not None:
        from transformers import pipeline
        logger.info("æˆåŠŸå¯¼å…¥transformers pipeline")
    else:
        # åœ¨æ²¡æœ‰torchçš„æƒ…å†µä¸‹ï¼Œè®¾ç½®pipelineä¸ºNone
        pipeline = None
        logger.warning("ç”±äºç¼ºå°‘torchï¼Œæ— æ³•å¯¼å…¥transformers pipeline")
except ImportError:
    logger.warning("æœªæ‰¾åˆ°transformersæ¨¡å—ï¼Œå°†ä½¿ç”¨è½»é‡çº§é™çº§æ–¹æ¡ˆ")
    pipeline = None

# ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥é…ç½®
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from config import (
    OPENAI_API_KEY, OPENAI_MODEL, HUGGINGFACE_API_KEY,
    MAX_TOKENS, TEMPERATURE, BATCH_SIZE, SENTIMENT_CLASSES, 
    EMOTION_CLASSES, CACHE_DIR
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®Hugging Face APIå¯†é’¥ï¼ˆå¦‚æœæä¾›ï¼‰
if HUGGINGFACE_API_KEY:
    os.environ["HUGGINGFACEHUB_API_TOKEN"] = HUGGINGFACE_API_KEY

# ç¼“å­˜æ–‡ä»¶è·¯å¾„
CACHE_FILE = os.path.join(CACHE_DIR, 'sentiment_analysis_cache.json')

class LLMSentimentAnalyzer:
    """ä½¿ç”¨LLMè¿›è¡Œæƒ…æ„Ÿåˆ†æçš„åˆ†æå™¨ï¼Œæ”¯æŒOpenAIã€Hugging Faceã€è±†åŒ…å’ŒDeepSeekæ¨¡å‹"""
    
    def __init__(self, model_name: Optional[str] = None, temperature: Optional[float] = None, 
                 model_type: str = "huggingface", show_progress: bool = True, init_model: bool = True):
        """
        åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
            temperature: ç”Ÿæˆæ¸©åº¦
            model_type: æ¨¡å‹ç±»å‹ï¼Œæ”¯æŒ"openai"ã€"huggingface"ã€"doubao"ã€"deepseek"æˆ–"local"
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œé€‚åˆè¯¾å ‚å±•ç¤º
            init_model: æ˜¯å¦ç«‹å³åˆå§‹åŒ–æ¨¡å‹ï¼ŒFalseè¡¨ç¤ºå»¶è¿Ÿåˆå§‹åŒ–ï¼Œæé«˜å¯åŠ¨é€Ÿåº¦
        """
        self.model_type = model_type.lower()
        self.temperature = temperature or TEMPERATURE
        self.show_progress = show_progress
        self.cache = self._load_cache()
        self.model_initialized = False
        
        # é¢„å®šä¹‰æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼ŒåŒ…å«é€‚åˆä¸­å›½å†…åœ°ç½‘ç»œç¯å¢ƒçš„æ¨¡å‹
        self.supported_models = {
            "huggingface": [
                "distilbert-base-uncased-finetuned-sst-2-english",
                "uer/roberta-base-finetuned-jd-binary-chinese",  # ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹
                "nghuyong/ernie-3.0-nano-zh"  # ç™¾åº¦ERNIEæ¨¡å‹ï¼Œå¯¹ä¸­æ–‡æ”¯æŒè¾ƒå¥½
            ],
            "local": [
                "rule-based-chinese",  # åŸºäºè§„åˆ™çš„ä¸­æ–‡åˆ†æ
                "rule-based-english"   # åŸºäºè§„åˆ™çš„è‹±æ–‡åˆ†æ
            ],
            "doubao": [
                "ERNIE-Bot-4",  # è±†åŒ…æ¨¡å‹
                "ERNIE-Bot-turbo"  # è±†åŒ…è½»é‡æ¨¡å‹
            ],
            "deepseek": [
                "deepseek-chat"  # DeepSeekå¯¹è¯æ¨¡å‹
            ]
        }
        
        # å­˜å‚¨æ¨¡å‹åç§°ï¼Œå»¶è¿Ÿåˆå§‹åŒ–
        self.model_name = model_name
        
        # å¦‚æœè®¾ç½®ä¸ºç«‹å³åˆå§‹åŒ–ï¼Œåˆ™åˆå§‹åŒ–æ¨¡å‹
        if init_model:
            self._initialize_model()
        else:
            # è®¾ç½®é»˜è®¤æ¨¡å‹åç§°
            if self.model_type == "openai":
                self.model_name = model_name or OPENAI_MODEL
            elif self.model_type == "huggingface":
                self.model_name = model_name or "distilbert-base-uncased-finetuned-sst-2-english"
            elif self.model_type == "local":
                self.model_name = model_name or "rule-based-chinese"
            elif self.model_type == "doubao":
                self.model_name = model_name or "ERNIE-Bot-4"
            elif self.model_type == "deepseek":
                self.model_name = model_name or "deepseek-chat"
            logger.info(f"å»¶è¿Ÿåˆå§‹åŒ–æ¨¡å‹: {self.model_type} - {self.model_name}")
            self.sentiment_pipeline = None
    
    def _initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹çš„å†…éƒ¨æ–¹æ³•ï¼Œæ”¯æŒå»¶è¿Ÿåˆå§‹åŒ–"""
        if self.model_initialized:
            return
        
        try:
            if self.model_type == "openai":
                # åˆå§‹åŒ–OpenAIæ¨¡å‹
                self.model_name = self.model_name or OPENAI_MODEL
                if not OPENAI_API_KEY:
                    logger.warning("OpenAI API key not provided, using Hugging Face fallback")
                    self.model_type = "huggingface"
                    self.model_name = self.model_name or "distilbert-base-uncased-finetuned-sst-2-english"
                    self._initialize_model()  # é€’å½’è°ƒç”¨ä»¥åˆå§‹åŒ–fallbackæ¨¡å‹
                else:
                    self.llm = ChatOpenAI(
                        model_name=self.model_name,
                        temperature=self.temperature,
                        max_tokens=MAX_TOKENS,
                        openai_api_key=OPENAI_API_KEY
                    )
                    logger.info(f"OpenAIæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {self.model_name}")
                    self.model_initialized = True
            
            elif self.model_type == "huggingface":
                # åˆå§‹åŒ–Hugging Faceæ¨¡å‹
                self.model_name = self.model_name or "distilbert-base-uncased-finetuned-sst-2-english"
                try:
                    # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
                    if pipeline is not None:
                        self.sentiment_pipeline = pipeline(
                            "sentiment-analysis", 
                            model=self.model_name,
                            device=-1  # ä½¿ç”¨CPUï¼Œç¡®ä¿åœ¨æ²¡æœ‰GPUçš„ç¯å¢ƒä¸­ä¹Ÿèƒ½è¿è¡Œ
                        )
                        logger.info(f"Hugging Faceæƒ…æ„Ÿåˆ†ææ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
                        self.model_initialized = True
                    else:
                        # é™çº§åˆ°è§„åˆ™åŸºç¡€çš„æƒ…æ„Ÿåˆ†æ
                        self.sentiment_pipeline = None
                        logger.info("é™çº§åˆ°è§„åˆ™åŸºç¡€çš„æƒ…æ„Ÿåˆ†æï¼Œé€‚åˆè¯¾å ‚æ¼”ç¤º")
                        self.model_initialized = True
                except Exception as e:
                    logger.error(f"åŠ è½½Hugging Faceæ¨¡å‹å‡ºé”™: {e}")
                    logger.info(f"å°è¯•ä½¿ç”¨æœ¬åœ°è§„åˆ™åˆ†æä½œä¸ºæ›¿ä»£æ–¹æ¡ˆ")
                    # é™çº§åˆ°ç®€å•å®ç°ï¼Œç¡®ä¿è¯¾å ‚æ¼”ç¤ºä¸ä¸­æ–­
                    self.sentiment_pipeline = None
                    self.model_type = "local"
                    self.model_name = "rule-based-chinese" if "chinese" in str(e) else "rule-based-english"
                    self.model_initialized = True
            
            elif self.model_type == "local":
                # åˆå§‹åŒ–æœ¬åœ°è§„åˆ™æ¨¡å‹
                self.model_name = self.model_name or "rule-based-chinese"
                logger.info(f"æœ¬åœ°è§„åˆ™æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {self.model_name}")
                self.sentiment_pipeline = None
                self.model_initialized = True
            
            elif self.model_type == "doubao":
                # åˆå§‹åŒ–è±†åŒ…æ¨¡å‹
                self.model_name = self.model_name or "ERNIE-Bot-4"
                # è±†åŒ…æ¨¡å‹é€šè¿‡APIè°ƒç”¨ï¼Œè¿™é‡Œåªåšå‡†å¤‡
                logger.info(f"è±†åŒ…æ¨¡å‹åˆå§‹åŒ–å‡†å¤‡å®Œæˆ: {self.model_name}")
                self.model_initialized = True
            
            elif self.model_type == "deepseek":
                # åˆå§‹åŒ–DeepSeekæ¨¡å‹
                self.model_name = self.model_name or "deepseek-chat"
                # DeepSeekæ¨¡å‹é€šè¿‡APIè°ƒç”¨ï¼Œè¿™é‡Œåªåšå‡†å¤‡
                logger.info(f"DeepSeekæ¨¡å‹åˆå§‹åŒ–å‡†å¤‡å®Œæˆ: {self.model_name}")
                self.model_initialized = True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # é™çº§åˆ°æœ¬åœ°è§„åˆ™æ¨¡å‹
            self.model_type = "local"
            self.model_name = "rule-based-chinese"
            self.sentiment_pipeline = None
            self.model_initialized = True
    
    def _load_cache(self) -> Dict[str, Any]:
        """åŠ è½½åˆ†æç¼“å­˜"""
        if os.path.exists(CACHE_FILE):
            try:
                with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"Error loading cache: {e}")
        return {}
    
    def _save_cache(self):
        """ä¿å­˜åˆ†æç¼“å­˜"""
        try:
            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Error saving cache: {e}")
    
    def _get_cache_key(self, text: str, analysis_type: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{analysis_type}:{text[:100]}:{self.model_name}:{self.model_type}"
    
    def _extract_json_from_response(self, response: str) -> Optional[Dict[str, Any]]:
        """ä»æ¨¡å‹å“åº”ä¸­æå–JSON"""
        try:
            # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            return json.loads(response)
        except json.JSONDecodeError:
            # å°è¯•æå–å“åº”ä¸­çš„JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{[^}]*\}', response)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except json.JSONDecodeError:
                    pass
        return None
    
    def _huggingface_analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨Hugging Faceæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œå¢å¼ºç‰ˆ"""
        try:
            if self.sentiment_pipeline:
                # å¯¹äºé•¿æ–‡æœ¬ï¼Œåˆ†æ®µå¤„ç†å¹¶å–å¹³å‡å€¼
                max_length = 512
                chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]
                
                if len(chunks) > 1:
                    # å¤šæ®µå¤„ç†ï¼Œè®¡ç®—å¹³å‡å¾—åˆ†
                    total_score = 0
                    total_weight = 0
                    
                    for i, chunk in enumerate(chunks):
                        # ç¬¬ä¸€æ®µå’Œæœ€åä¸€æ®µæƒé‡æ›´é«˜
                        weight = 1.5 if i == 0 or i == len(chunks) - 1 else 1.0
                        chunk_result = self.sentiment_pipeline(chunk)[0]
                        
                        chunk_score = chunk_result["score"]
                        if chunk_result["label"] == "NEGATIVE":
                            chunk_score = -chunk_score
                        
                        total_score += chunk_score * weight
                        total_weight += weight
                    
                    final_score = total_score / total_weight if total_weight > 0 else 0
                else:
                    # å•æ®µå¤„ç†
                    result = self.sentiment_pipeline(text[:max_length])[0]
                    final_score = result["score"]
                    if result["label"] == "NEGATIVE":
                        final_score = -final_score
                
                # æ ¹æ®åˆ†æ•°ç¡®å®šæƒ…æ„Ÿ
                if final_score > 0.3:
                    sentiment = "æ­£é¢"
                    confidence = abs(final_score)
                elif final_score < -0.3:
                    sentiment = "è´Ÿé¢"
                    confidence = abs(final_score)
                else:
                    sentiment = "ä¸­æ€§"
                    # ä¸­æ€§æƒ…æ„Ÿçš„ç½®ä¿¡åº¦åŸºäºä¸é˜ˆå€¼çš„è·ç¦»
                    confidence = 1.0 - (abs(final_score) / 0.3)
                    confidence = max(0.5, min(0.9, confidence))  # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
                
                score = final_score
            else:
                # å¢å¼ºçš„è§„åˆ™åˆ†æä½œä¸ºåå¤‡æ–¹æ¡ˆ
                # æ‰©å±•çš„å…³é”®è¯åˆ—è¡¨
                positive_keywords = {
                    "å¥½": 1.0, "å–œæ¬¢": 1.2, "ä¼˜ç§€": 1.5, "æ£’": 1.2, "èµ": 1.0,
                    "great": 1.0, "good": 1.0, "excellent": 1.5, "love": 1.2,
                    "å¼€å¿ƒ": 1.0, "å¿«ä¹": 1.2, "æ»¡æ„": 1.0, "æ¨è": 1.0, "æ”¯æŒ": 0.8,
                    "ç²¾å½©": 1.2, "å®Œç¾": 1.5, "å‡ºè‰²": 1.3, "å¾ˆå¥½": 1.2, "ä¸é”™": 0.8,
                    "wonderful": 1.3, "amazing": 1.4, "fantastic": 1.3, "terrific": 1.2,
                    "é«˜å…´": 1.0, "æ„‰å¿«": 1.0, "èˆ’æœ": 0.8, "ä¾¿åˆ©": 0.7, "å€¼å¾—": 0.9
                }
                
                negative_keywords = {
                    "å·®": 1.0, "ç³Ÿç³•": 1.3, "ä¸å¥½": 1.0, "è®¨åŒ": 1.2, "çƒ‚": 1.4,
                    "bad": 1.0, "terrible": 1.4, "awful": 1.3, "hate": 1.2,
                    "å¤±æœ›": 1.2, "ç”Ÿæ°”": 1.3, "éš¾è¿‡": 1.1, "ä¸æ»¡": 1.0, "è´µ": 0.8,
                    "åƒåœ¾": 1.5, "æ¶å¿ƒ": 1.4, "çƒ¦": 1.0, "æ— èŠ": 0.9, "è´µ": 0.8,
                    "poor": 1.1, "disappointed": 1.2, "angry": 1.3, "terrible": 1.4,
                    "çƒ¦èº": 1.0, "éƒé—·": 0.9, "ç—›è‹¦": 1.3, "ä¼¤å¿ƒ": 1.2, "å¤±è´¥": 1.1
                }
                
                # å¦å®šè¯å’Œç¨‹åº¦è¯
                negation_words = {"ä¸", "æ²¡", "æ— ", "é", "å¦", "æœª", "åˆ«", "å‹¿"}
                intensifier_words = {"å¾ˆ": 1.5, "éå¸¸": 2.0, "ç‰¹åˆ«": 1.8, "ååˆ†": 1.7, "æå…¶": 2.2}
                
                text_lower = text.lower()
                score = 0.0
                confidence = 0.5
                found_keywords = []
                
                # æ£€æµ‹æ ‡ç‚¹ç¬¦å·çš„æƒ…æ„Ÿå¢å¼ºä½œç”¨
                exclamation_count = sum(1 for char in text if char in ['!', 'ï¼'])
                question_count = sum(1 for char in text if char in ['?', 'ï¼Ÿ'])
                
                # æ„Ÿå¹å·å¢å¼ºæƒ…æ„Ÿå¼ºåº¦
                punctuation_factor = 1.0 + (exclamation_count * 0.3)
                punctuation_factor = min(punctuation_factor, 2.0)
                
                # é—®å·å¯èƒ½è¡¨ç¤ºç–‘é—®æˆ–è½»å¾®è´Ÿé¢
                question_effect = -0.1 * question_count
                question_effect = max(-0.3, question_effect)
                
                # æ£€æŸ¥ç¨‹åº¦è¯
                for word, weight in intensifier_words.items():
                    if word in text_lower:
                        punctuation_factor *= weight
                        punctuation_factor = min(punctuation_factor, 3.0)
                        break
                
                # ç»Ÿè®¡å…³é”®è¯å¹¶è®¡ç®—å¾—åˆ†
                negation_active = False
                total_weight = 0
                
                # å…ˆæ£€æŸ¥å¦å®šè¯
                for word in negation_words:
                    if word in text_lower:
                        negation_active = True
                        break
                
                # ç»Ÿè®¡ç§¯æå…³é”®è¯
                for word, weight in positive_keywords.items():
                    if word in text_lower:
                        word_score = weight
                        if negation_active:
                            word_score = -word_score
                        score += word_score
                        total_weight += abs(weight)
                        found_keywords.append(word)
                
                # ç»Ÿè®¡æ¶ˆæå…³é”®è¯
                for word, weight in negative_keywords.items():
                    if word in text_lower:
                        word_score = -weight
                        if negation_active:
                            word_score = -word_score
                        score += word_score
                        total_weight += abs(weight)
                        found_keywords.append(word)
                
                # åº”ç”¨æ ‡ç‚¹ç¬¦å·å’Œé—®é¢˜æ ‡è®°çš„å½±å“
                score = score * punctuation_factor + question_effect
                
                # å½’ä¸€åŒ–åˆ†æ•°
                if total_weight > 0:
                    # åŸºäºæ‰¾åˆ°çš„å…³é”®è¯æ•°é‡å’Œæƒé‡å½’ä¸€åŒ–
                    normalized_score = score / total_weight
                    # é™åˆ¶åœ¨[-1, 1]èŒƒå›´å†…
                    score = max(-1.0, min(1.0, normalized_score))
                
                # è®¡ç®—ç½®ä¿¡åº¦ï¼šåŸºäºå…³é”®è¯æ•°é‡å’Œæƒ…æ„Ÿå¼ºåº¦
                if total_weight > 0:
                    # å…³é”®è¯è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜
                    confidence = min(0.95, 0.5 + (len(found_keywords) * 0.1))
                    # æƒ…æ„Ÿè¶Šå¼ºçƒˆï¼Œç½®ä¿¡åº¦è¶Šé«˜
                    confidence += min(0.05, abs(score) * 0.1)
                else:
                    # æ²¡æœ‰æ‰¾åˆ°å…³é”®è¯ï¼Œä½†æœ‰æ ‡ç‚¹ç¬¦å·
                    if exclamation_count > 0:
                        sentiment = "æ­£é¢" if exclamation_count > question_count else "ä¸­æ€§"
                        score = 0.2 if sentiment == "æ­£é¢" else 0.0
                        confidence = 0.5
                    elif question_count > 0:
                        sentiment = "ä¸­æ€§"
                        score = -0.1 * question_count
                        confidence = 0.4
                    else:
                        sentiment = "ä¸­æ€§"
                        score = 0.0
                        confidence = 0.3
                
                # ç¡®å®šæœ€ç»ˆæƒ…æ„Ÿ
                if score > 0.2:
                    sentiment = "æ­£é¢"
                elif score < -0.2:
                    sentiment = "è´Ÿé¢"
                else:
                    sentiment = "ä¸­æ€§"
                    # ä¸­æ€§æƒ…æ„Ÿçš„ç½®ä¿¡åº¦ç•¥ä½
                    confidence = max(0.3, confidence - 0.1)
            
            # å…³é”®è¯å·²åœ¨è§„åˆ™åˆ†æä¸­æå–
            
            return {
                "sentiment": sentiment,
                "score": score,
                "confidence": confidence,
                "keywords": found_keywords[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®è¯
            }
        except Exception as e:
            logger.error(f"Error in Hugging Face sentiment analysis: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return {
                "sentiment": "ä¸­æ€§",
                "score": 0.0,
                "confidence": 0.5,
                "keywords": []
            }
    
    def _huggingface_analyze_emotion(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨Hugging Faceæ¨¡å‹è¿›è¡Œæƒ…ç»ªåˆ†æ"""
        try:
            # ä½¿ç”¨ç®€å•çš„è§„åˆ™è¿›è¡Œæƒ…ç»ªåˆ†ç±»ï¼ˆé€‚åˆè¯¾å ‚å±•ç¤ºï¼‰
            emotion_patterns = {
                "å–œæ‚¦": ["å¼€å¿ƒ", "å¿«ä¹", "é«˜å…´", "å…´å¥‹", "å–œæ‚¦", "happy", "joy", "excited", "glad"],
                "æ„¤æ€’": ["ç”Ÿæ°”", "æ„¤æ€’", "æ°”æ­»", "æ€’", "angry", "furious", "mad"],
                "æ‚²ä¼¤": ["éš¾è¿‡", "ä¼¤å¿ƒ", "æ‚²ä¼¤", "æ²®ä¸§", "sad", "depressed", "upset"],
                "ææƒ§": ["å®³æ€•", "ææƒ§", "ææ€–", "æ€•", "fear", "scared", "terrified"],
                "æƒŠè®¶": ["æƒŠè®¶", "éœ‡æƒŠ", "æ²¡æƒ³åˆ°", "å“‡", "surprised", "shocked", "amazed"],
                "åŒæ¶": ["åŒæ¶", "è®¨åŒ", "æ¶å¿ƒ", "disgust", "hate", "dislike"],
                "ä¿¡ä»»": ["ä¿¡ä»»", "ç›¸ä¿¡", "å¯é ", "trust", "believe", "reliable"],
                "æœŸå¾…": ["æœŸå¾…", "æœŸæœ›", "ç›¼æœ›", "æœŸå¾…", "expect", "look forward", "anticipate"]
            }
            
            emotion_scores = {emotion: 0.0 for emotion in EMOTION_CLASSES.values()}
            text_lower = text.lower()
            
            # è®¡ç®—æ¯ç§æƒ…ç»ªçš„å¾—åˆ†
            for emotion, patterns in emotion_patterns.items():
                for pattern in patterns:
                    if pattern.lower() in text_lower:
                        emotion_scores[emotion] += 0.3
            
            # å½’ä¸€åŒ–å¾—åˆ†
            total_score = sum(emotion_scores.values())
            if total_score > 0:
                for emotion in emotion_scores:
                    emotion_scores[emotion] = min(1.0, emotion_scores[emotion])
            
            # æ‰¾å‡ºä¸»è¦æƒ…ç»ª
            primary_emotion = max(emotion_scores, key=emotion_scores.get)
            if emotion_scores[primary_emotion] == 0:
                primary_emotion = "æ— "
            
            confidence = emotion_scores[primary_emotion] if primary_emotion != "æ— " else 0.5
            
            return {
                "primary_emotion": primary_emotion,
                "emotion_scores": emotion_scores,
                "confidence": confidence
            }
        except Exception as e:
            logger.error(f"Error in Hugging Face emotion analysis: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            default_scores = {emotion: 0.0 for emotion in EMOTION_CLASSES.values()}
            return {
                "primary_emotion": "æ— ",
                "emotion_scores": default_scores,
                "confidence": 0.5
            }
    
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text, 'sentiment')
        if cache_key in self.cache:
            logger.info(f"Cache hit for text: {text[:30]}...")
            return self.cache[cache_key]
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        self._initialize_model()
        
        if self.model_type == "openai":
            # OpenAIæ¨¡å‹çš„å¤„ç†é€»è¾‘
            # æ„å»ºæç¤ºæ¨¡æ¿
            prompt_template = ChatPromptTemplate.from_template("""
            åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
            
            æ–‡æœ¬: "{text}"
            
            è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ç»“æœï¼ˆè¯·ç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
            {{
                "sentiment": "æ­£é¢"æˆ–"è´Ÿé¢"æˆ–"ä¸­æ€§",
                "score": -1åˆ°1ä¹‹é—´çš„æ•°å­—ï¼Œå…¶ä¸­-1è¡¨ç¤ºæåº¦è´Ÿé¢ï¼Œ1è¡¨ç¤ºæåº¦æ­£é¢,
                "confidence": 0åˆ°1ä¹‹é—´çš„æ•°å­—ï¼Œè¡¨ç¤ºåˆ†æçš„ç½®ä¿¡åº¦,
                "keywords": [ä¸æƒ…æ„Ÿç›¸å…³çš„å…³é”®è¯åˆ—è¡¨]
            }}
            """)
            
            # åˆ›å»ºé“¾å¹¶æ‰§è¡Œ
            chain = LLMChain(llm=self.llm, prompt=prompt_template)
            response = chain.run(text=text)
            
            # æå–ç»“æœ
            result = self._extract_json_from_response(response)
            
            # å¦‚æœæ— æ³•æå–JSONï¼Œä½¿ç”¨åå¤‡è§£æ
            if result is None:
                logger.warning(f"Failed to parse JSON from response: {response}")
                # ç®€å•çš„è§„åˆ™è§£æä½œä¸ºåå¤‡
                result = {
                    "sentiment": "ä¸­æ€§",
                    "score": 0.0,
                    "confidence": 0.5,
                    "keywords": []
                }
        elif self.model_type == "doubao":
            # è±†åŒ…æ¨¡å‹çš„å¤„ç†é€»è¾‘
            result = self._doubao_analyze_sentiment(text)
        elif self.model_type == "deepseek":
            # DeepSeekæ¨¡å‹çš„å¤„ç†é€»è¾‘
            result = self._deepseek_analyze_sentiment(text)
        else:
            # Hugging Faceæ¨¡å‹æˆ–æœ¬åœ°è§„åˆ™æ¨¡å‹çš„å¤„ç†é€»è¾‘
            result = self._huggingface_analyze_sentiment(text)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self.cache[cache_key] = result
        self._save_cache()
        
        return result
    
    def analyze_emotion(self, text: str) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªæ–‡æœ¬çš„æƒ…ç»ª"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text, 'emotion')
        if cache_key in self.cache:
            logger.info(f"Cache hit for text: {text[:30]}...")
            return self.cache[cache_key]
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        self._initialize_model()
        
        if self.model_type == "openai":
            # OpenAIæ¨¡å‹çš„å¤„ç†é€»è¾‘
            # æ„å»ºæç¤ºæ¨¡æ¿
            prompt_template = ChatPromptTemplate.from_template("""
            åˆ†æä»¥ä¸‹æ–‡æœ¬è¡¨è¾¾çš„æƒ…ç»ªï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
            
            æ–‡æœ¬: "{text}"
            
            è¯·è¯†åˆ«ä¸»è¦æƒ…ç»ªå’Œå¼ºåº¦ï¼Œå¹¶æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ç»“æœï¼ˆè¯·ç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
            {{
                "primary_emotion": "å–œæ‚¦"æˆ–"æ„¤æ€’"æˆ–"æ‚²ä¼¤"æˆ–"ææƒ§"æˆ–"æƒŠè®¶"æˆ–"åŒæ¶"æˆ–"ä¿¡ä»»"æˆ–"æœŸå¾…"æˆ–"æ— ",
                "emotion_scores": {{
                    "å–œæ‚¦": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "æ„¤æ€’": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "æ‚²ä¼¤": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "ææƒ§": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "æƒŠè®¶": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "åŒæ¶": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "ä¿¡ä»»": 0åˆ°1ä¹‹é—´çš„æ•°å­—,
                    "æœŸå¾…": 0åˆ°1ä¹‹é—´çš„æ•°å­—
                }},
                "confidence": 0åˆ°1ä¹‹é—´çš„æ•°å­—
            }}
            """)
            
            # åˆ›å»ºé“¾å¹¶æ‰§è¡Œ
            chain = LLMChain(llm=self.llm, prompt=prompt_template)
            response = chain.run(text=text)
            
            # æå–ç»“æœ
            result = self._extract_json_from_response(response)
            
            # å¦‚æœæ— æ³•æå–JSONï¼Œä½¿ç”¨åå¤‡è§£æ
            if result is None:
                logger.warning(f"Failed to parse JSON from response: {response}")
                # é»˜è®¤ç»“æœ
                default_scores = {emotion: 0.0 for emotion in EMOTION_CLASSES.values()}
                result = {
                    "primary_emotion": "æ— ",
                    "emotion_scores": default_scores,
                    "confidence": 0.5
                }
        elif self.model_type == "doubao":
            # è±†åŒ…æ¨¡å‹çš„å¤„ç†é€»è¾‘ï¼Œä½¿ç”¨Hugging Faceçš„æƒ…ç»ªåˆ†æä½œä¸ºåå¤‡
            result = self._huggingface_analyze_emotion(text)
        elif self.model_type == "deepseek":
            # DeepSeekæ¨¡å‹çš„å¤„ç†é€»è¾‘ï¼Œä½¿ç”¨Hugging Faceçš„æƒ…ç»ªåˆ†æä½œä¸ºåå¤‡
            result = self._huggingface_analyze_emotion(text)
        else:
            # Hugging Faceæ¨¡å‹çš„å¤„ç†é€»è¾‘
            result = self._huggingface_analyze_emotion(text)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self.cache[cache_key] = result
        self._save_cache()
        
        return result
    
    def analyze_sentiment_batch(self, texts: List[str], batch_size: Optional[int] = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        batch_size = batch_size or BATCH_SIZE
        results = []
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        self._initialize_model()
        
        # å¯¹äºHugging Faceæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥æ›´é«˜æ•ˆåœ°å¤„ç†
        if self.model_type == "huggingface":
            # åˆ†æ‰¹å¤„ç†
            iterator = range(0, len(texts), batch_size)
            if self.show_progress:
                iterator = tqdm(iterator, desc="æƒ…æ„Ÿåˆ†æä¸­")
            for i in iterator:
                batch = texts[i:i+batch_size]
                batch_results = []
                
                for text in batch:
                    try:
                        # æ£€æŸ¥ç¼“å­˜
                        cache_key = self._get_cache_key(text, 'sentiment')
                        if cache_key in self.cache:
                            batch_results.append(self.cache[cache_key])
                        else:
                            result = self._huggingface_analyze_sentiment(text)
                            self.cache[cache_key] = result
                            batch_results.append(result)
                    except Exception as e:
                        logger.error(f"Error analyzing text: {text[:30]}... Error: {e}")
                        # æ·»åŠ é»˜è®¤ç»“æœ
                        batch_results.append({
                            "sentiment": "ä¸­æ€§",
                            "score": 0.0,
                            "confidence": 0.0,
                            "keywords": []
                        })
                
                results.extend(batch_results)
            
            # ä¿å­˜ç¼“å­˜
            self._save_cache()
            return results
        
        # OpenAIæ¨¡å‹çš„æ‰¹å¤„ç†é€»è¾‘
        # åˆ†æ‰¹å¤„ç†
        iterator = range(0, len(texts), batch_size)
        if self.show_progress:
            iterator = tqdm(iterator, desc="æƒ…æ„Ÿåˆ†æä¸­")
        for i in iterator:
            batch = texts[i:i+batch_size]
            batch_results = []
            
            for text in batch:
                try:
                    result = self.analyze_sentiment(text)
                    batch_results.append(result)
                except Exception as e:
                    logger.error(f"Error analyzing text: {text[:30]}... Error: {e}")
                    # æ·»åŠ é»˜è®¤ç»“æœ
                    batch_results.append({
                        "sentiment": "ä¸­æ€§",
                        "score": 0.0,
                        "confidence": 0.0,
                        "keywords": []
                    })
            
            results.extend(batch_results)
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶ï¼ˆä»…OpenAIéœ€è¦ï¼‰
            if i + batch_size < len(texts):
                time.sleep(1)
        
        return results
    
    def analyze_emotion_batch(self, texts: List[str], batch_size: Optional[int] = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡åˆ†ææ–‡æœ¬æƒ…ç»ª"""
        batch_size = batch_size or BATCH_SIZE
        results = []
        
        # ç¡®ä¿æ¨¡å‹å·²åˆå§‹åŒ–
        self._initialize_model()
        
        # å¯¹äºHugging Faceæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥æ›´é«˜æ•ˆåœ°å¤„ç†
        if self.model_type == "huggingface":
            # åˆ†æ‰¹å¤„ç†
            iterator = range(0, len(texts), batch_size)
            if self.show_progress:
                iterator = tqdm(iterator, desc="æƒ…ç»ªåˆ†æä¸­")
            for i in iterator:
                batch = texts[i:i+batch_size]
                batch_results = []
                
                for text in batch:
                    try:
                        # æ£€æŸ¥ç¼“å­˜
                        cache_key = self._get_cache_key(text, 'emotion')
                        if cache_key in self.cache:
                            batch_results.append(self.cache[cache_key])
                        else:
                            result = self._huggingface_analyze_emotion(text)
                            self.cache[cache_key] = result
                            batch_results.append(result)
                    except Exception as e:
                        logger.error(f"Error analyzing emotion for text: {text[:30]}... Error: {e}")
                        # æ·»åŠ é»˜è®¤ç»“æœ
                        default_scores = {emotion: 0.0 for emotion in EMOTION_CLASSES.values()}
                        batch_results.append({
                            "primary_emotion": "æ— ",
                            "emotion_scores": default_scores,
                            "confidence": 0.0
                        })
                
                results.extend(batch_results)
            
            # ä¿å­˜ç¼“å­˜
            self._save_cache()
            return results
        
        # OpenAIæ¨¡å‹çš„æ‰¹å¤„ç†é€»è¾‘
        # åˆ†æ‰¹å¤„ç†
        iterator = range(0, len(texts), batch_size)
        if self.show_progress:
            iterator = tqdm(iterator, desc="æƒ…ç»ªåˆ†æä¸­")
        for i in iterator:
            batch = texts[i:i+batch_size]
            batch_results = []
            
            for text in batch:
                try:
                    result = self.analyze_emotion(text)
                    batch_results.append(result)
                except Exception as e:
                    logger.error(f"Error analyzing emotion for text: {text[:30]}... Error: {e}")
                    # æ·»åŠ é»˜è®¤ç»“æœ
                    default_scores = {emotion: 0.0 for emotion in EMOTION_CLASSES.values()}
                    batch_results.append({
                        "primary_emotion": "æ— ",
                        "emotion_scores": default_scores,
                        "confidence": 0.0
                    })
            
            results.extend(batch_results)
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶ï¼ˆä»…OpenAIéœ€è¦ï¼‰
            if i + batch_size < len(texts):
                time.sleep(1)
        
        return results
    
    def analyze_dataframe(self, df: pd.DataFrame, text_column: str) -> pd.DataFrame:
        """åˆ†æDataFrameä¸­çš„æ–‡æœ¬åˆ—"""
        # è·å–æ–‡æœ¬åˆ—è¡¨
        texts = df[text_column].tolist()
        
        # åˆ†ææƒ…æ„Ÿ
        sentiment_results = self.analyze_sentiment_batch(texts)
        
        # åˆ†ææƒ…ç»ª
        emotion_results = self.analyze_emotion_batch(texts)
        
        # å°†ç»“æœæ·»åŠ åˆ°DataFrame
        sentiment_df = pd.DataFrame(sentiment_results)
        emotion_df = pd.DataFrame(emotion_results)
        
        # åˆå¹¶ç»“æœ
        result_df = df.copy()
        result_df = pd.concat([result_df, sentiment_df.add_prefix('sentiment_')], axis=1)
        result_df = pd.concat([result_df, emotion_df.add_prefix('emotion_')], axis=1)
        
        # å°†æƒ…ç»ªåˆ†æ•°å±•å¼€ä¸ºå•ç‹¬çš„åˆ—
        emotion_scores_df = pd.DataFrame([r.get('emotion_scores', {}) for r in emotion_results])
        result_df = pd.concat([result_df, emotion_scores_df.add_prefix('emotion_score_')], axis=1)
        
        return result_df
    
    def _doubao_analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨è±†åŒ…æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
        try:
            # è±†åŒ…æ¨¡å‹APIè°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰
            # è¿™é‡Œä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦é…ç½®æ­£ç¡®çš„APIè°ƒç”¨
            logger.info(f"ä½¿ç”¨è±†åŒ…æ¨¡å‹åˆ†ææ–‡æœ¬æƒ…æ„Ÿ: {text[:30]}...")
            
            # å°è¯•è·å–è±†åŒ…APIå¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­ï¼‰
            doubao_api_key = os.environ.get('DOUBAO_API_KEY', '')
            
            if doubao_api_key:
                # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„è±†åŒ…APIè°ƒç”¨é€»è¾‘
                # ç”±äºæ˜¯æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡
                pass
            
            # ä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡
            return self._huggingface_analyze_sentiment(text)
            
        except Exception as e:
            logger.error(f"è±†åŒ…æ¨¡å‹æƒ…æ„Ÿåˆ†æå‡ºé”™: {e}")
            # è¿”å›è§„åˆ™åˆ†æç»“æœä½œä¸ºåå¤‡
            return self._huggingface_analyze_sentiment(text)
    
    def _deepseek_analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨DeepSeekæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ"""
        try:
            # DeepSeekæ¨¡å‹APIè°ƒç”¨ç¤ºä¾‹ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰
            # è¿™é‡Œä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡ï¼Œå®é™…é¡¹ç›®ä¸­éœ€è¦é…ç½®æ­£ç¡®çš„APIè°ƒç”¨
            logger.info(f"ä½¿ç”¨DeepSeekæ¨¡å‹åˆ†ææ–‡æœ¬æƒ…æ„Ÿ: {text[:30]}...")
            
            # å°è¯•è·å–DeepSeek APIå¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­ï¼‰
            deepseek_api_key = os.environ.get('DEEPSEEK_API_KEY', '')
            
            if deepseek_api_key:
                # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„DeepSeek APIè°ƒç”¨é€»è¾‘
                # ç”±äºæ˜¯æ¼”ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡
                pass
            
            # ä½¿ç”¨è§„åˆ™åˆ†æä½œä¸ºåå¤‡
            return self._huggingface_analyze_sentiment(text)
            
        except Exception as e:
            logger.error(f"DeepSeekæ¨¡å‹æƒ…æ„Ÿåˆ†æå‡ºé”™: {e}")
            # è¿”å›è§„åˆ™åˆ†æç»“æœä½œä¸ºåå¤‡
            return self._huggingface_analyze_sentiment(text)
    
    def check_connection(self, quick_check: bool = True, timeout: float = 5.0) -> bool:
        """
        æ£€æŸ¥æ¨¡å‹è¿æ¥çŠ¶æ€
        
        Args:
            quick_check: æ˜¯å¦è¿›è¡Œå¿«é€Ÿæ£€æŸ¥ï¼ˆä¸å°è¯•åˆå§‹åŒ–æ¨¡å‹ï¼‰
            timeout: è¿æ¥æ£€æŸ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            bool: æ¨¡å‹è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        import signal
        from contextlib import contextmanager
        
        @contextmanager
        def timeout_context(seconds):
            """è¶…æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
            def timeout_handler(signum, frame):
                raise TimeoutError("è¿æ¥æ£€æŸ¥è¶…æ—¶")
                
            # è®¾ç½®ä¿¡å·å¤„ç†
            old_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(int(seconds))
            
            try:
                yield
            finally:
                signal.alarm(0)
                signal.signal(signal.SIGALRM, old_handler)
        
        try:
            if self.model_type == "local":
                # æœ¬åœ°æ¨¡å‹æ€»æ˜¯å¯ç”¨çš„
                return True
            elif self.model_type == "huggingface":
                # å¿«é€Ÿæ£€æŸ¥æ¨¡å¼ä¸‹ä¸å°è¯•åˆå§‹åŒ–
                if quick_check:
                    # åªæ£€æŸ¥æ˜¯å¦å·²ç»åˆå§‹åŒ–æˆåŠŸ
                    return hasattr(self, 'sentiment_pipeline') and self.sentiment_pipeline is not None
                
                # éå¿«é€Ÿæ¨¡å¼ä¸‹å°è¯•åˆå§‹åŒ–ï¼Œä½†æ·»åŠ è¶…æ—¶æ§åˆ¶
                if not self.model_initialized:
                    try:
                        # ä»…åœ¨Windowsä»¥å¤–çš„ç³»ç»Ÿä½¿ç”¨è¶…æ—¶æ§åˆ¶
                        if os.name != 'nt':  # Windowsä¸æ”¯æŒSIGALRM
                            with timeout_context(timeout):
                                self._initialize_model()
                        else:
                            self._initialize_model()
                    except (Exception, TimeoutError):
                        return False
                return hasattr(self, 'sentiment_pipeline') and self.sentiment_pipeline is not None
            elif self.model_type in ["doubao", "deepseek"]:
                # å¯¹äºAPIæ¨¡å‹ï¼Œè¿›è¡Œè½»é‡çº§æ£€æŸ¥
                # å¿«é€Ÿæ¨¡å¼ä¸‹åªæ£€æŸ¥APIå¯†é’¥é…ç½®çŠ¶æ€
                if quick_check:
                    # ä¸è¿›è¡Œå®é™…çš„APIè°ƒç”¨ï¼Œåªæ£€æŸ¥ç¯å¢ƒæ˜¯å¦é…ç½®
                    return True  # ä¸ºäº†å¿«é€Ÿå“åº”ï¼Œé»˜è®¤è¿”å›å¯ç”¨ï¼Œå®é™…ä½¿ç”¨æ—¶æ‰éªŒè¯
                
                # éå¿«é€Ÿæ¨¡å¼ä¸‹æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
                api_key = os.environ.get(f'{self.model_type.upper()}_API_KEY', '')
                return True  # å³ä½¿æ²¡æœ‰APIå¯†é’¥ä¹Ÿè¿”å›Trueï¼Œå› ä¸ºæœ‰åå¤‡æ–¹æ¡ˆ
            elif self.model_type == "openai":
                # å¿«é€Ÿæ£€æŸ¥æ¨¡å¼ä¸‹ç›´æ¥è¿”å›çŠ¶æ€
                if quick_check:
                    return True  # é»˜è®¤è¿”å›å¯ç”¨
                return bool(OPENAI_API_KEY)
            return False
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ¨¡å‹è¿æ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False

# ç¤ºä¾‹ç”¨æ³• - è¯¾å ‚æ¼”ç¤ºç‰ˆæœ¬
if __name__ == "__main__":
    print("\n===== ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æç³»ç»Ÿæ¼”ç¤ºï¼ˆè¯¾å ‚ç‰ˆï¼‰ =====\n")
    
    # ç¤ºä¾‹æ–‡æœ¬ - ä¸°å¯Œå¤šæ ·ï¼Œé€‚åˆè¯¾å ‚å±•ç¤º
    sample_texts = [
        "è¿™æ¬¾æ–°æ‰‹æœºçš„æ€§èƒ½å¤ªæ£’äº†ï¼Œæ‹ç…§æ•ˆæœè¶…å‡ºé¢„æœŸï¼",
        "ä»Šå¤©é‡åˆ°äº†éå¸¸ç³Ÿç³•çš„å®¢æˆ·æœåŠ¡ï¼Œå¤ªä»¤äººå¤±æœ›äº†ã€‚",
        "è¿™ä¸ªç”µå½±æƒ…èŠ‚ä¸€èˆ¬ï¼Œä½†æ¼”å‘˜çš„è¡¨æ¼”è¿˜ä¸é”™ã€‚",
        "å…¬å¸è£å‘˜çš„æ¶ˆæ¯è®©æˆ‘æ„Ÿåˆ°éå¸¸å®³æ€•å’Œç„¦è™‘ã€‚",
        "æ”¶åˆ°äº†å¿ƒä»ªå·²ä¹…çš„ç¤¼ç‰©ï¼Œæˆ‘å¤ªå¼€å¿ƒäº†ï¼",
        "å¯¹è¿™æ¬¡çš„äº§å“å‘å¸ƒä¼šå……æ»¡æœŸå¾…ï¼Œå¸Œæœ›èƒ½å¸¦æ¥æƒŠå–œã€‚",
        "æˆ‘å®Œå…¨ä¿¡ä»»è¿™ä¸ªå“ç‰Œçš„è´¨é‡å’Œä¿¡èª‰ã€‚"
    ]
    
    # åˆ›å»ºåˆ†æå™¨ - ä½¿ç”¨Hugging Faceå…è´¹æ¨¡å‹ï¼ˆè¯¾å ‚æ¼”ç¤ºä¸“ç”¨ï¼‰
    print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–Hugging Faceå…è´¹æƒ…æ„Ÿåˆ†ææ¨¡å‹...\n")
    analyzer = LLMSentimentAnalyzer(
        model_type="huggingface", 
        show_progress=True  # æ˜¾ç¤ºè¿›åº¦æ¡ï¼Œå¢å¼ºè¯¾å ‚æ¼”ç¤ºæ•ˆæœ
    )
    
    # å•æ–‡æœ¬åˆ†æ - è¯¾å ‚å®æ—¶æ¼”ç¤º
    print("ğŸ“Š å•æ–‡æœ¬æƒ…æ„Ÿä¸æƒ…ç»ªåˆ†ææ¼”ç¤ºï¼š\n")
    
    # ä¸ºæ¯ä¸ªæ–‡æœ¬è¿›è¡Œåˆ†æå¹¶å±•ç¤ºç»“æœ
    for i, text in enumerate(sample_texts):
        print(f"\n{'='*60}")
        print(f"æ–‡æœ¬ {i+1}: {text}")
        print(f"{'='*60}")
        
        # å®æ—¶åˆ†ææƒ…æ„Ÿ
        print("ğŸ” æ­£åœ¨åˆ†ææƒ…æ„Ÿ...")
        sentiment = analyzer.analyze_sentiment(text)
        
        # æ ¼å¼åŒ–è¾“å‡ºæƒ…æ„Ÿåˆ†æç»“æœ
        print(f"\næƒ…æ„Ÿåˆ†æç»“æœ:")
        print(f"   æƒ…æ„Ÿå€¾å‘: {sentiment['sentiment']}")
        print(f"   æƒ…æ„Ÿå¾—åˆ†: {sentiment['score']:.2f}")
        print(f"   ç½®ä¿¡åº¦: {sentiment['confidence']:.2f}")
        print(f"   å…³é”®æƒ…æ„Ÿè¯: {', '.join(sentiment['keywords']) if sentiment['keywords'] else 'æ— '}")
        
        # å®æ—¶åˆ†ææƒ…ç»ª
        print("\nğŸ˜Š æ­£åœ¨åˆ†ææƒ…ç»ª...")
        emotion = analyzer.analyze_emotion(text)
        
        # æ ¼å¼åŒ–è¾“å‡ºæƒ…ç»ªåˆ†æç»“æœ
        print(f"\næƒ…ç»ªåˆ†æç»“æœ:")
        print(f"   ä¸»è¦æƒ…ç»ª: {emotion['primary_emotion']}")
        print(f"   æƒ…ç»ªå¼ºåº¦: {emotion['confidence']:.2f}")
        print(f"\n   å„æƒ…ç»ªå¼ºåº¦åˆ†å¸ƒ:")
        
        # æŒ‰å¼ºåº¦æ’åºæ˜¾ç¤ºå„æƒ…ç»ª
        sorted_emotions = sorted(emotion['emotion_scores'].items(), 
                               key=lambda x: x[1], reverse=True)
        
        for emotion_name, score in sorted_emotions:
            if score > 0:
                # å¯è§†åŒ–å¼ºåº¦
                bar_length = int(score * 20)
                print(f"     {emotion_name}: {score:.2f} {'â–ˆ' * bar_length}")
    
    # æ‰¹é‡åˆ†ææ¼”ç¤º
    print("\n\nğŸ“ˆ æ‰¹é‡åˆ†ææ¼”ç¤ºï¼š")
    print(f"æ­£åœ¨åŒæ—¶åˆ†æ {len(sample_texts)} æ¡æ–‡æœ¬...\n")
    
    sentiment_results = analyzer.analyze_sentiment_batch(sample_texts)
    emotion_results = analyzer.analyze_emotion_batch(sample_texts)
    
    # ç»Ÿè®¡ç»“æœ
    sentiment_counts = {}
    emotion_counts = {}
    
    for sentiment in sentiment_results:
        s = sentiment['sentiment']
        sentiment_counts[s] = sentiment_counts.get(s, 0) + 1
    
    for emotion in emotion_results:
        e = emotion['primary_emotion']
        emotion_counts[e] = emotion_counts.get(e, 0) + 1
    
    # å±•ç¤ºç»Ÿè®¡ç»“æœ
    print("ğŸ“Š æ‰¹é‡åˆ†æç»Ÿè®¡ç»“æœ:")
    print("\næƒ…æ„Ÿåˆ†å¸ƒ:")
    for sentiment, count in sentiment_counts.items():
        percentage = (count / len(sample_texts)) * 100
        print(f"   {sentiment}: {count}æ¡ ({percentage:.1f}%)")
    
    print("\nä¸»è¦æƒ…ç»ªåˆ†å¸ƒ:")
    for emotion, count in emotion_counts.items():
        percentage = (count / len(sample_texts)) * 100
        print(f"   {emotion}: {count}æ¡ ({percentage:.1f}%)")
    
    print("\n\nâœ… æ¼”ç¤ºå®Œæˆï¼ç³»ç»Ÿä½¿ç”¨Hugging Faceå…è´¹æ¨¡å‹ï¼Œæ— éœ€APIå¯†é’¥å³å¯è¿è¡Œã€‚")
    print("é€‚åˆè¯¾å ‚å®ç‰©å±•ç¤ºçš„ç‰¹ç‚¹:")
    print("1. å®Œå…¨å…è´¹ï¼Œæ— éœ€æ”¯ä»˜APIè´¹ç”¨")
    print("2. æœ¬åœ°è¿è¡Œï¼Œå“åº”é€Ÿåº¦å¿«")
    print("3. ç›´è§‚çš„è¿›åº¦æ¡å’Œæ ¼å¼åŒ–è¾“å‡º")
    print("4. æ”¯æŒå®æ—¶æ¼”ç¤ºå’Œæ‰¹é‡åˆ†æ")
    print("5. æœ‰é™çº§æ–¹æ¡ˆï¼Œç¡®ä¿åœ¨ä»»ä½•ç¯å¢ƒä¸­éƒ½èƒ½è¿è¡Œ")